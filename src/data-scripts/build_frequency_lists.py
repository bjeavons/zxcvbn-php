#!/usr/bin/python
import os
import sys
import time
import codecs
import json

from operator import itemgetter
from collections import deque

def usage():
    return '''
usage:
%s data-dir frequency_lists.coffee [config]

generates frequency_lists.coffee (zxcvbn's ranked dictionary file) from word frequency data.
data-dir should contain frequency counts, as generated by the data-scripts/count_* scripts.

config - name of json configuration file from data-dir: default, cs, cs_small ...

Configuration file controls which frequency data will be included and at maximum
how many tokens per dictionary.

If a token appears in multiple frequency lists, it will only appear once in emitted .coffee file,
in the dictionary where it has lowest rank.

Short tokens, if rare, are also filtered out. If a token has higher rank than 10**(token.length),
it will be excluded because a bruteforce match would have given it a lower guess score.

A warning will be printed if DICTIONARIES contains a dictionary name that doesn't appear in
passed data dir, or vice-versa.
    ''' % sys.argv[0]

# maps dict name to num words. None value means "include all words"
DEFAULT_DICTIONARIES = dict(
    us_tv_and_film    = 30000,
    english_wikipedia = 30000,
    passwords         = 30000,
    surnames          = 10000,
    male_names        = None,
    female_names      = None,
)

MIN_GUESSES_BEFORE_GROWING_SEQUENCE = 1000
MIN_TOKEN_LENGTH = 3
BRUTAL_MIN_LENGTH = 5

# returns {list_name: {token: rank}}, as tokens and ranks occur in each file.
def parse_frequency_lists(data_dir, dictionaries):
    freq_lists = {}
    for filename in os.listdir(data_dir):
        freq_list_name, ext = os.path.splitext(filename)
        if ext == ".json":  # skip config files
            continue
        if freq_list_name not in dictionaries:
            msg = 'Info: %s appears in %s directory but not in DICTIONARY settings. Excluding.'
            print(msg % (freq_list_name, data_dir))
            continue
        tokens = deque()
        with codecs.open(os.path.join(data_dir, filename), 'r', 'utf8') as f:
            for i, line in enumerate(f):
                rank = i + 1
                token = line.split()[0]
                if is_rare_and_short(token, rank):
                    continue
                if has_only_one_char(token):
                    continue
                if has_comma_or_double_quote(token, rank, freq_list_name):
                    continue
                tokens.append(token)
        freq_lists[freq_list_name] = tokens
    for freq_list_name in dictionaries:
        if freq_list_name not in freq_lists:
            msg = 'Warning: %s appears in DICTIONARY settings but not in %s directory. Excluding.'
            print(msg % (freq_list_name, data_dir))
    return freq_lists

def is_rare_and_short(token, rank):
    return len(token) < MIN_TOKEN_LENGTH or rank >= 10**len(token)

def has_only_one_char(token):
    return len(set(token)) == 1

def has_comma_or_double_quote(token, rank, lst_name):
    # hax, switch to csv or similar if this excludes too much.
    # simple comma joining has the advantage of being easy to process
    # client-side w/o needing a lib, and so far this only excludes a few
    # very high-rank tokens eg 'ps8,000' at rank 74868 from wikipedia list.
    if ',' in token or '"' in token:
        return True
    return False

def is_brutal_better(token, rank, minimum_rank):
    if rank < MIN_GUESSES_BEFORE_GROWING_SEQUENCE:
        return False
    if len(token) < BRUTAL_MIN_LENGTH:
        return False
    short_token = token[:-1]
    if short_token in minimum_rank:
        srank = minimum_rank[short_token]
        if rank > ( srank * 22 ) + MIN_GUESSES_BEFORE_GROWING_SEQUENCE:
            #print ("brutal: %s %s short: %s %s" % (token, rank, short_token, srank))
            return True
    return False

def filter_frequency_lists2(freq_lists, dictionaries):
    '''
    filters frequency data according to:
        - filter out short tokens if they are too rare.
        - filter out tokens if they already appear in another dict
          at lower rank.
        - cut off final freq_list at limits set in DICTIONARIES, if any.
    '''
    result = {}
    for name in freq_lists:
        result[name] = []
    minimum_rank = {} # maps token -> lowest token rank across all freq lists
   
    rank = 0
    is_next_token = True
    while is_next_token:
        rank = rank + 1
        is_next_token = False
        for name in sorted(freq_lists):
            cutoff_limit = dictionaries[name]
            token = first_uniq_token (freq_lists[name], minimum_rank, rank)
            if token and (not cutoff_limit or rank <= cutoff_limit):
                minimum_rank[token]=rank
                result[name].append(token)
                is_next_token = True

    for name in sorted(result):
        # debug message
        msg = 'Debug: dictionary %s, tokens: %s, last_token: %s'
        print(msg % (name, len(result[name]), result[name][-1]))
    return result

def first_uniq_token(freq_list, minimum_rank, rank):
    if len(freq_list) == 0:
        return None
    first_token = freq_list.popleft()
    if first_token in minimum_rank or is_brutal_better(first_token, rank, minimum_rank):
        return first_uniq_token(freq_list, minimum_rank, rank)
    else:
        return first_token

def to_kv(lst, lst_name):
    val = '"%s".split(",")' % ','.join(lst)
    return '%s: %s' % (lst_name, val)

def read_config(data_dir, config_file):
    filename = config_file
    if not filename.endswith('.json'):
        filename += '.json'
    if filename.find("/") < 0:
        filename = data_dir + '/' + filename
    try:
        with open(filename) as json_data_file:
            data = json.load(json_data_file)
        if 'dictionaries' in data:
            return data['dictionaries']
        else:
            msg = 'Warning: missing key "dictionaries" in config file %s. Using default dictionaries.'
            print(msg % (filename))
    except IOError as e:
        msg = 'Warning: cannot read config file %s: %s. Using default dictionaries.'
        print(msg % (filename, e.strerror))
    return DEFAULT_DICTIONARIES

def main():
    if len(sys.argv) == 3:
        data_dir, output_file = sys.argv[1:]
        dictionaries = DEFAULT_DICTIONARIES
    elif len(sys.argv) == 4:
        data_dir, output_file, config_file = sys.argv[1:]
        dictionaries = read_config(data_dir, config_file)
    else:
        print(usage())
        sys.exit(0)
    unfiltered_freq_lists = parse_frequency_lists(data_dir, dictionaries)
    freq_lists = filter_frequency_lists2(unfiltered_freq_lists, dictionaries)
    with codecs.open(output_file, 'w', 'utf8') as f:
        script_name = os.path.split(sys.argv[0])[1]
        f.write('# generated by %s\n' % script_name)
        f.write('frequency_lists = \n  ')
        lines = []
        for name, lst in sorted(freq_lists.items()):
            lines.append(to_kv(lst, name))
        f.write('\n  '.join(lines))
        f.write('\n')
        f.write('module.exports = frequency_lists\n')

if __name__ == '__main__':
    main()

